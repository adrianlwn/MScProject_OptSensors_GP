
@article{arcucci_optimal_2019,
	title = {Optimal reduced space for {Variational} {Data} {Assimilation}},
	volume = {379},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118307095},
	doi = {10.1016/j.jcp.2018.10.042},
	abstract = {Data Assimilation (DA) is an uncertainty quantiﬁcation technique used to incorporate observed data into a prediction model in order to improve numerical forecasted results. Variational DA (VarDA) is based on the minimisation of a function which estimates the discrepancy between numerical results and observations. Operational forecasting requires real-time data assimilation. This mandates the choice of opportune methods to improve the eﬃciency of VarDA codes without loosing accuracy. Due to the scale of the forecasting area and the number of state variables used to describe the physical model, DA is a big data problem. In this paper, the Truncated Singular Value Decomposition (TSVD) is used to reduce the space dimension, alleviate the computational cost and reduce the errors. Nevertheless, a consequence is that important information is lost if the truncation parameter is not properly chosen. We provide an algorithm to compute the optimal truncation parameter and we prove that the optimal estimation reduces the illconditioning and removes the statistically less signiﬁcant modes which could add noise to the estimate obtained from DA. In this paper, numerical issues faced in developing VarDA algorithm include the ill-conditioning of the background covariance matrix, the choice of a preconditioning and the choice of the regularisation parameter. We also show how the choice of the regularisation parameter impacts on the eﬃciency of the VarDA minimisation computed by the L-BFGS (Limited – Broyden Fletcher Goldfarb Shanno). Experimental results are provided for pollutant dispersion within an urban environment.},
	language = {en},
	urldate = {2019-04-15},
	journal = {Journal of Computational Physics},
	author = {Arcucci, Rossella and Mottet, Laetitia and Pain, Christopher and Guo, Yi-Ke},
	month = feb,
	year = {2019},
	pages = {51--69},
	file = {Arcucci et al. - 2019 - Optimal reduced space for Variational Data Assimil.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/initial papers/Arcucci et al. - 2019 - Optimal reduced space for Variational Data Assimil.pdf:application/pdf}
}

@article{krause_near-optimal_2008,
	title = {Near-{Optimal} {Sensor} {Placements} in {Gaussian} {Processes}: {Theory}, {Efﬁcient} {Algorithms} and {Empirical} {Studies}},
	abstract = {When monitoring spatial phenomena, which can often be modeled as Gaussian processes (GPs), choosing sensor locations is a fundamental task. There are several common strategies to address this task, for example, geometry or disk models, placing sensors at the points of highest entropy (variance) in the GP model, and A-, D-, or E-optimal design. In this paper, we tackle the combinatorial optimization problem of maximizing the mutual information between the chosen locations and the locations which are not selected. We prove that the problem of ﬁnding the conﬁguration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 − 1/e) of the optimum by exploiting the submodularity of mutual information. We also show how submodularity can be used to obtain online bounds, and design branch and bound search procedures. We then extend our algorithm to exploit lazy evaluations and local structure in the GP, yielding signiﬁcant speedups. We also extend our approach to ﬁnd placements which are robust against node failures and uncertainties in the model. These extensions are again associated with rigorous theoretical approximation guarantees, exploiting the submodularity of the objective function. We demonstrate the advantages of our approach towards optimizing mutual information in a very extensive empirical study on two real-world data sets.},
	language = {en},
	author = {Krause, Andreas and Singh, Ajit and Guestrin, Carlos},
	year = {2008},
	pages = {50},
	file = {Krause et al. - 2008 - Near-Optimal Sensor Placements in Gaussian Process.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/initial papers/Krause et al. - 2008 - Near-Optimal Sensor Placements in Gaussian Process.pdf:application/pdf}
}

@article{song_natural_2018,
	title = {Natural ventilation in cities: the implications of fluid mechanics},
	volume = {46},
	issn = {0961-3218, 1466-4321},
	shorttitle = {Natural ventilation in cities},
	url = {https://www.tandfonline.com/doi/full/10.1080/09613218.2018.1468158},
	doi = {10.1080/09613218.2018.1468158},
	abstract = {Research under the Managing Air for Green Inner Cities (MAGIC) project uses measurements and modelling to investigate the connections between external and internal conditions: the impact of urban airﬂow on the natural ventilation of a building. The test site was chosen so that under diﬀerent environmental conditions the levels of external pollutants entering the building, from either a polluted road or a relatively clean courtyard, would be signiﬁcantly diﬀerent. Measurements included temperature, relative humidity, local wind and solar radiation, together with levels of carbon monoxide (CO) and carbon dioxide (CO2) both inside and outside the building to assess the indoor–outdoor exchange ﬂows. Building ventilation took place through windows on two sides, allowing for single-sided and crosswind-driven ventilation, and also stackdriven ventilation in low wind conditions. The external ﬂow around the test site was modelled in an urban boundary layer in a wind tunnel. The wind tunnel results were incorporated in a largeeddy-simulation model, Fluidity, and the results compared with monitoring data taken both within the building and from the surrounding area. In particular, the eﬀects of street layout and associated street canyons, of roof geometry and the wakes of nearby tall buildings were examined.},
	language = {en},
	number = {8},
	urldate = {2019-04-15},
	journal = {Building Research \& Information},
	author = {Song, Jiyun and Fan, S. and Lin, W. and Mottet, L. and Woodward, H. and Davies Wykes, M. and Arcucci, R. and Xiao, D. and Debay, J.-E. and ApSimon, H. and Aristodemou, E. and Birch, D. and Carpentieri, M. and Fang, F. and Herzog, M. and Hunt, G. R. and Jones, R. L. and Pain, C. and Pavlidis, D. and Robins, A. G. and Short, C. A. and Linden, P. F.},
	month = nov,
	year = {2018},
	pages = {809--828},
	file = {Natural ventilation in cities the implications of fluid mechanics.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/initial papers/Natural ventilation in cities the implications of fluid mechanics.pdf:application/pdf}
}

@inproceedings{guestrin_near-optimal_2005,
	address = {Bonn, Germany},
	title = {Near-optimal sensor placements in {Gaussian} processes},
	isbn = {978-1-59593-180-1},
	url = {http://portal.acm.org/citation.cfm?doid=1102351.1102385},
	doi = {10.1145/1102351.1102385},
	abstract = {When monitoring spatial phenomena, which are often modeled as Gaussian Processes (GPs), choosing sensor locations is a fundamental task. A common strategy is to place sensors at the points of highest entropy (variance) in the GP model. We propose a mutual information criteria, and show that it produces better placements. Furthermore, we prove that ﬁnding the conﬁguration that maximizes mutual information is NP-complete. To address this issue, we describe a polynomial-time approximation that is within (1 − 1/e) of the optimum by exploiting the submodularity of our criterion. This algorithm is extended to handle local structure in the GP, yielding signiﬁcant speedups. We demonstrate the advantages of our approach on two real-world data sets.},
	language = {en},
	urldate = {2019-04-15},
	booktitle = {Proceedings of the 22nd international conference on {Machine} learning  - {ICML} '05},
	publisher = {ACM Press},
	author = {Guestrin, Carlos and Krause, Andreas and Singh, Ajit Paul},
	year = {2005},
	pages = {265--272},
	file = {Guestrin et al. - 2005 - Near-optimal sensor placements in Gaussian process.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/initial papers/Guestrin et al. - 2005 - Near-optimal sensor placements in Gaussian process.pdf:application/pdf}
}

@article{law_data_2015,
	title = {Data {Assimilation}: {A} {Mathematical} {Introduction}},
	shorttitle = {Data {Assimilation}},
	url = {http://arxiv.org/abs/1506.07825},
	abstract = {These notes provide a systematic mathematical treatment of the subject of data assimilation.},
	urldate = {2019-04-15},
	journal = {arXiv:1506.07825 [math, stat]},
	author = {Law, K. J. H. and Stuart, A. M. and Zygalakis, K. C.},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.07825},
	keywords = {Mathematics - Dynamical Systems, Mathematics - Optimization and Control, Statistics - Methodology},
	file = {arXiv.org Snapshot:/Users/adrian/Zotero/storage/LKCPR6YU/1506.html:text/html;Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:/Users/adrian/Zotero/storage/SPAUV7FU/Law et al. - 2015 - Data Assimilation A Mathematical Introduction.pdf:application/pdf}
}

@article{arcucci_variational_2017,
	title = {On the variational data assimilation problem solving and sensitivity analysis},
	volume = {335},
	issn = {00219991},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999117300505},
	doi = {10.1016/j.jcp.2017.01.034},
	abstract = {We consider the Variational Data Assimilation (VarDA) problem in an operational framework, namely, as it results when it is employed for the analysis of temperature and salinity variations of data collected in closed and semi closed seas. We present a computing approach to solve the main computational kernel at the heart of the VarDA problem, which outperforms the technique nowadays employed by the oceanographic operative software. The new approach is obtained by means of Tikhonov regularization. We provide the sensitivity analysis of this approach and we also study its performance in terms of the accuracy gain on the computed solution. We provide validations on two realistic oceanographic data sets.},
	language = {en},
	urldate = {2019-04-20},
	journal = {Journal of Computational Physics},
	author = {Arcucci, Rossella and D'Amore, Luisa and Pistoia, Jenny and Toumi, Ralf and Murli, Almerico},
	month = apr,
	year = {2017},
	pages = {311--326},
	file = {Arcucci et al. - 2017 - On the variational data assimilation problem solvi.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Data Assimilation/Arcucci et al. - 2017 - On the variational data assimilation problem solvi.pdf:application/pdf}
}

@misc{noauthor_mutual_2019,
	title = {Mutual information},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Mutual_information&oldid=892560218},
	abstract = {In probability theory and information theory, the mutual information (MI) of two random variables is a measure of the mutual dependence between the two variables. More specifically, it quantifies the "amount of information" (in units such as shannons, commonly called bits) obtained about one random variable through observing the other random variable.  The concept of mutual information is intricately linked to that of entropy of a random variable, a fundamental notion in information theory that quantifies the expected "amount of information" held in a random variable.
Not limited to real-valued random variables like the correlation coefficient, MI is more general and determines how similar the joint distribution of the pair 
  
    
      
        (
        X
        ,
        Y
        )
      
    
    \{{\textbackslash}displaystyle (X,Y)\}
   is to the product of the marginal distributions of 
  
    
      
        X
      
    
    \{{\textbackslash}displaystyle X\}
   and 
  
    
      
        Y
      
    
    \{{\textbackslash}displaystyle Y\}
  . MI is the expected value of the pointwise mutual information (PMI).},
	language = {en},
	urldate = {2019-04-26},
	journal = {Wikipedia},
	month = apr,
	year = {2019},
	note = {Page Version ID: 892560218},
	file = {Snapshot:/Users/adrian/Zotero/storage/22PMAS6S/index.html:text/html}
}

@article{nott_estimation_2002,
	title = {Estimation of nonstationary spatial covariance structure},
	volume = {89},
	issn = {0006-3444, 1464-3510},
	url = {https://academic.oup.com/biomet/article-lookup/doi/10.1093/biomet/89.4.819},
	doi = {10.1093/biomet/89.4.819},
	abstract = {We introduce a method for estimating nonstationary spatial covariance structure from space-time data and apply the method to an analysis of Sydney wind patterns. Our method constructs a process honouring a given spatial covariance matrix at observing stations and uses one or more stationary processes to describe conditional behaviour given observing site values. The stationary processes give a localised description of the spatial covariance structure. The method is computationally attractive, and can be extended to the assessment of covariance for multivariate processes. The technique is illustrated for data describing the east-west component of Sydney winds. For this example, our own methods are contrasted with a geometrically appealing though computationally intensive technique which describes spatial correlation via an isotropic process and a deformation of the geographical space.},
	language = {en},
	number = {4},
	urldate = {2019-05-01},
	journal = {Biometrika},
	author = {Nott, D. J. and Dunsmuir, W. T. M.},
	month = dec,
	year = {2002},
	pages = {819--829},
	file = {Nott and Dunsmuir - 2002 - Estimation of nonstationary spatial covariance str.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Nott and Dunsmuir - 2002 - Estimation of nonstationary spatial covariance str.pdf:application/pdf}
}

@incollection{bordeaux_submodular_2013,
	address = {Cambridge},
	title = {Submodular {Function} {Maximization}},
	isbn = {978-1-139-17780-1},
	url = {https://www.cambridge.org/core/product/identifier/CBO9781139177801A031/type/book_part},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {Tractability},
	publisher = {Cambridge University Press},
	author = {Krause, Andreas and Golovin, Daniel},
	editor = {Bordeaux, Lucas and Hamadi, Youssef and Kohli, Pushmeet and Mateescu, Robert},
	year = {2013},
	doi = {10.1017/CBO9781139177801.004},
	pages = {71--104},
	file = {Krause and Golovin - 2013 - Submodular Function Maximization.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Submodularity/Krause and Golovin - 2013 - Submodular Function Maximization.pdf:application/pdf}
}

@article{nemhauser_analysis_1978,
	title = {An analysis of approximations for maximizing submodular set functions—{I}},
	volume = {14},
	issn = {0025-5610, 1436-4646},
	url = {http://link.springer.com/10.1007/BF01588971},
	doi = {10.1007/BF01588971},
	abstract = {Let N be a finite set and z be a real-valued function defined on the set of subsets of N that satisfies z ( S ) + z ( T ) {\textgreater} - z ( S U T ) + z ( S n T ) for all S, T in N. Such a function is called submodular. We consider the problem maXscN \{z(S): IS[ {\textless}-K, z(S) submodular\}. Several hard combinatorial optimization problems can be posed in this framework. For example, the problem of finding a maximum weight independent set in a matroid, when the elements of the matroid are colored and the elements of the independent set can have no more than K colors, is in this class. The uncapacitated location problem is a special case of this matroid optimization problem. We analyze greedy and local improvement heuristics and a linear programming relaxation for this problem. Our results are worst case bounds on the quality of the approximations. For example, when z(S) is nondecreasing and z(0) = 0, we.show that a "greedy" heuristic always produces a solution whose value is at least 1 - [ ( K - 1 ) / K ] K times the optimal value. This bound can be achieved for each K and has a limiting value of ( e - l)/e, where e is the base of the natural logarithm.},
	language = {en},
	number = {1},
	urldate = {2019-05-02},
	journal = {Mathematical Programming},
	author = {Nemhauser, G. L. and Wolsey, L. A. and Fisher, M. L.},
	month = dec,
	year = {1978},
	pages = {265--294},
	file = {Nemhauser et al. - 1978 - An analysis of approximations for maximizing submo.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Submodularity/Nemhauser et al. - 1978 - An analysis of approximations for maximizing submo.pdf:application/pdf}
}

@inproceedings{leskovec_cost-effective_2007,
	address = {San Jose, California, USA},
	title = {Cost-effective outbreak detection in networks},
	isbn = {978-1-59593-609-7},
	url = {http://portal.acm.org/citation.cfm?doid=1281192.1281239},
	doi = {10.1145/1281192.1281239},
	abstract = {Given a water distribution network, where should we place sensors to quickly detect contaminants? Or, which blogs should we read to avoid missing important stories? These seemingly diﬀerent problems share common structure: Outbreak detection can be modeled as selecting nodes (sensor locations, blogs) in a network, in order to detect the spreading of a virus or information as quickly as possible.},
	language = {en},
	urldate = {2019-05-02},
	booktitle = {Proceedings of the 13th {ACM} {SIGKDD} international conference on {Knowledge} discovery and data mining  - {KDD} '07},
	publisher = {ACM Press},
	author = {Leskovec, Jure and Krause, Andreas and Guestrin, Carlos and Faloutsos, Christos and VanBriesen, Jeanne and Glance, Natalie},
	year = {2007},
	pages = {420},
	file = {Leskovec et al. - 2007 - Cost-effective outbreak detection in networks.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Submodularity/Other Applications/Leskovec et al. - 2007 - Cost-effective outbreak detection in networks.pdf:application/pdf}
}

@article{deisenroth_distributed_nodate,
	title = {Distributed {Gaussian} {Processes}},
	abstract = {To scale Gaussian processes (GPs) to large data sets we introduce the robust Bayesian Committee Machine (rBCM), a practical and scalable product-of-experts model for large-scale distributed GP regression. Unlike state-of-theart sparse GP approximations, the rBCM is conceptually simple and does not rely on inducing or variational parameters. The key idea is to recursively distribute computations to independent computational units and, subsequently, recombine them to form an overall result. Efﬁcient closed-form inference allows for straightforward parallelisation and distributed computations with a small memory footprint. The rBCM is independent of the computational graph and can be used on heterogeneous computing infrastructures, ranging from laptops to clusters. With sufﬁcient computing resources our distributed GP model can handle arbitrarily large data sets.},
	language = {en},
	author = {Deisenroth, Marc Peter and Ng, Jun Wei},
	pages = {10},
	file = {Deisenroth and Ng - Distributed Gaussian Processes.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Scalability/Deisenroth and Ng - Distributed Gaussian Processes.pdf:application/pdf}
}

@book{cressie_statistics_1991,
	address = {New York},
	series = {Wiley series in probability and mathematical statistics},
	title = {Statistics for spatial data},
	isbn = {978-0-471-84336-8},
	publisher = {Wiley},
	author = {Cressie, Noel A. C.},
	year = {1991},
	keywords = {Spatial analysis (Statistics)},
	file = {Cressie - 1991 - Statistics for spatial data.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Cressie - 1991 - Statistics for spatial data.pdf:application/pdf}
}

@misc{noauthor_stationary_2019,
	title = {Stationary process},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Stationary_process&oldid=887919881},
	abstract = {In mathematics and statistics, a stationary process (a.k.a. a strict/strictly stationary process or strong/strongly stationary process) is a stochastic process whose unconditional joint probability distribution does not change when shifted in time. Consequently, parameters such as mean and variance also do not change over time.
Since stationarity is an assumption underlying many statistical procedures used in time series analysis, non-stationary data is often transformed to become stationary. The most common cause of violation of stationarity is a trend in the mean, which can be due either to the presence of a unit root or of a deterministic trend. In the former case of a unit root, stochastic shocks have permanent effects, and the process is not mean-reverting. In the latter case of a deterministic trend, the process is called a trend stationary process, and stochastic shocks have only transitory effects after which the variable tends toward a deterministically evolving (non-constant) mean.
A trend stationary process is not strictly stationary, but can easily be transformed into a stationary process by removing the underlying trend, which is solely a function of time. Similarly, processes with one or more unit roots can be made stationary through differencing. An important type of non-stationary process that does not include a trend-like behavior is a cyclostationary process, which is a stochastic process that varies cyclically with time.
For many applications strict-sense stationarity is too restrictive. Other forms of stationarity such as wide-sense stationarity or N-th order stationarity are then employed. The definitions for different kinds of stationarity are not consistent among different authors (see Other terminology).},
	language = {en},
	urldate = {2019-05-02},
	journal = {Wikipedia},
	month = mar,
	year = {2019},
	note = {Page Version ID: 887919881},
	file = {Snapshot:/Users/adrian/Zotero/storage/GH5L2HT4/index.html:text/html}
}

@article{zhu_model_2019,
	title = {Model error correction in data assimilation by integrating neural networks},
	volume = {2},
	issn = {2096-0654},
	url = {https://ieeexplore.ieee.org/document/8665726/},
	doi = {10.26599/BDMA.2018.9020033},
	abstract = {In this paper, we suggest a new methodology which combines Neural Networks (NN) into Data Assimilation (DA). Focusing on the structural model uncertainty, we propose a framework for integration NN with the physical models by DA algorithms, to improve both the assimilation process and the forecasting results. The NNs are iteratively trained as observational data is updated. The main DA models used here are the Kalman ﬁlter and the variational approaches. The effectiveness of the proposed algorithm is validated by examples and by a sensitivity study.},
	language = {en},
	number = {2},
	urldate = {2019-05-06},
	journal = {Big Data Mining and Analytics},
	author = {Zhu, Jiangcheng and Hu, Shuang and Arcucci, Rossella and Xu, Chao and Zhu, Jihong and Guo, Yi-ke},
	month = jun,
	year = {2019},
	pages = {83--91},
	file = {Zhu et al. - 2019 - Model error correction in data assimilation by int.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Data Assimilation/Zhu et al. - 2019 - Model error correction in data assimilation by int.pdf:application/pdf}
}

@article{arcucci_effective_2018,
	title = {Effective variational data assimilation in air-pollution prediction},
	volume = {1},
	issn = {2096-0654},
	url = {https://ieeexplore.ieee.org/document/8400446/},
	doi = {10.26599/BDMA.2018.9020025},
	abstract = {Numerical simulations are widely used as a predictive tool to better understand complex air ﬂows and pollution transport on the scale of individual buildings, city blocks, and entire cities. To improve prediction for air ﬂows and pollution transport, we propose a Variational Data Assimilation (VarDA) model which assimilates data from sensors into the open-source, ﬁnite-element, ﬂuid dynamics model Fluidity. VarDA is based on the minimization of a function which estimates the discrepancy between numerical results and observations assuming that the two sources of information, forecast and observations, have errors that are adequately described by error covariance matrices. The conditioning of the numerical problem is dominated by the condition number of the background error covariance matrix which is ill-conditioned. In this paper, a preconditioned VarDA model is presented, it is based on a reduced background error covariance matrix. The Empirical Orthogonal Functions (EOFs) method is used to alleviate the computational cost and reduce the space dimension. Experimental results are provided assuming observed values provided by sensors from positions mainly located on roofs of buildings.},
	language = {en},
	number = {4},
	urldate = {2019-05-06},
	journal = {Big Data Mining and Analytics},
	author = {Arcucci, Rossella and Pain, Christopher and Guo, Yi-Ke},
	month = dec,
	year = {2018},
	pages = {297--307},
	file = {Arcucci et al. - 2018 - Effective variational data assimilation in air-pol.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Data Assimilation/Arcucci et al. - 2018 - Effective variational data assimilation in air-pol.pdf:application/pdf}
}

@incollection{monestiez_advances_2001,
	address = {Dordrecht},
	title = {Advances in {Modeling} and {Inference} for {Environmental} {Processes} with {Nonstationary} {Spatial} {Covariance}},
	volume = {11},
	isbn = {978-0-7923-7107-6 978-94-010-0810-5},
	url = {http://www.springerlink.com/index/10.1007/978-94-010-0810-5_2},
	urldate = {2019-05-16},
	booktitle = {{geoENV} {III} — {Geostatistics} for {Environmental} {Applications}},
	publisher = {Springer Netherlands},
	author = {Sampson, P. D. and Damian, D. and Guttorp, P.},
	editor = {Monestiez, Pascal and Allard, Denis and Froidevaux, Roland},
	year = {2001},
	doi = {10.1007/978-94-010-0810-5_2},
	pages = {17--32},
	file = {Sampson et al. - 2001 - Advances in Modeling and Inference for Environment.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Sampson et al. - 2001 - Advances in Modeling and Inference for Environment.pdf:application/pdf}
}

@incollection{guttorp_20_1994,
	title = {20 {Methods} for estimating heterogeneous spatial covariance functions with environmental applications},
	volume = {12},
	isbn = {978-0-444-89803-6},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169716105800227},
	abstract = {Estimation of spatial covariance is important to many statistical problems in the analysis of environmental monitoring data. In this Chapter we review several difrerent methods for spati.al covariance estimation from monitoring data, with emphasis on methods for heterogeneous models. We briefly describe some applications, and outline how these methods can be extended to space-time and multivariate models.},
	language = {en},
	urldate = {2019-05-16},
	booktitle = {Handbook of {Statistics}},
	publisher = {Elsevier},
	author = {Guttorp, Peter and Sampson, Paul D.},
	year = {1994},
	doi = {10.1016/S0169-7161(05)80022-7},
	pages = {661--689},
	file = {Guttorp and Sampson - 1994 - 20 Methods for estimating heterogeneous spatial co.pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Guttorp and Sampson - 1994 - 20 Methods for estimating heterogeneous spatial co.pdf:application/pdf}
}

@article{liu_when_2018,
	title = {When {Gaussian} {Process} {Meets} {Big} {Data}: {A} {Review} of {Scalable} {GPs}},
	shorttitle = {When {Gaussian} {Process} {Meets} {Big} {Data}},
	url = {http://arxiv.org/abs/1807.01065},
	abstract = {The vast quantity of information brought by big data as well as the evolving computer hardware encourages success stories in the machine learning community. In the meanwhile, it poses challenges for the Gaussian process (GP) regression, a well-known non-parametric and interpretable Bayesian model, which suffers from cubic complexity to data size. To improve the scalability while retaining desirable prediction quality, a variety of scalable GPs have been presented. But they have not yet been comprehensively reviewed and analyzed in order to be well understood by both academia and industry. The review of scalable GPs in the GP community is timely and important due to the explosion of data size. To this end, this paper is devoted to the review on state-of-the-art scalable GPs involving two main categories: global approximations which distillate the entire data and local approximations which divide the data for subspace learning. Particularly, for global approximations, we mainly focus on sparse approximations comprising prior approximations which modify the prior but perform exact inference, posterior approximations which retain exact prior but perform approximate inference, and structured sparse approximations which exploit speciﬁc structures in kernel matrix; for local approximations, we highlight the mixture/product of experts that conducts model averaging from multiple local experts to boost predictions. To present a complete review, recent advances for improving the scalability and capability of scalable GPs are reviewed. Finally, the extensions and open issues regarding the implementation of scalable GPs in various scenarios are reviewed and discussed to inspire novel ideas for future research avenues.},
	language = {en},
	urldate = {2019-05-16},
	journal = {arXiv:1807.01065 [cs, stat]},
	author = {Liu, Haitao and Ong, Yew-Soon and Shen, Xiaobo and Cai, Jianfei},
	month = jul,
	year = {2018},
	note = {arXiv: 1807.01065},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Liu et al. - 2018 - When Gaussian Process Meets Big Data A Review of .pdf:/Users/adrian/Documents/2019/Imperial College/T3/Master Project.nosync/MScProject_OptSensors_GP/Gaussian Processes/Scalability/Liu et al. - 2018 - When Gaussian Process Meets Big Data A Review of .pdf:application/pdf}
}